# LLM Model Evaluation

This project evaluates various LLAMA models using different prompting methods. The evaluation is based on a dataset of text samples.

## Requirements

- Python 3.x
- OpenAI Python package
- Matplotlib
- dotenv (for loading environment variables)

## Installation

1. Clone the repository:
   ```bash
   git clone https://github.com/yourusername/your-repo.git
   cd your-repo

2. Install the required packages:
```bash
   pip install -r requirements.txt
```
3. Create a .env file in the root directory and add your API key:

## Configuration
Edit the `llm_config.json` file to modify the models and prompting methods used in the evaluation.

## Usage

Run the main script to execute the model evaluation:
```bash
python main.py
```